{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5kNuToe15t4"
   },
   "source": [
    "## 0 - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2713,
     "status": "ok",
     "timestamp": 1632324447532,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "XPHI71nA1yqo",
    "outputId": "262fdf15-d97d-45b7-89b9-64a891146f65"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import RobertaTokenizerFast, RobertaConfig\n",
    "\n",
    "from roberta import generate_data_loader, train, evaluate, plot_curves, RobertaExtraction, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NNuBqOy1yq2"
   },
   "source": [
    "## 1 - Train Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "0SSafeBW1yq3",
    "outputId": "5617052b-e93f-471d-fd8b-be17505a2e5e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else : \n",
    "    device = torch.device('cpu')\n",
    "\n",
    "root_path = './'\n",
    "config = RobertaConfig.from_pretrained('distilroberta-base')\n",
    "model = RobertaExtraction(config).to(device)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "batch_size = 4\n",
    "train_path, dev_path, test_path = root_path + 'data/dataset/train_ds.pkl', root_path + 'data/dataset/dev_ds.pkl', root_path + 'data/dataset/test_ds.pkl'\n",
    "train_dataset, train_data_loader, dev_dataset, dev_data_loader, test_dataset, test_data_loader = generate_data_loader(batch_size, \n",
    "                                                                                                                      train_path, \n",
    "                                                                                                                      dev_path, \n",
    "                                                                                                                      test_path, \n",
    "                                                                                                                      tokenizer)\n",
    "\n",
    "epochs = 4\n",
    "accumulation_steps = 10\n",
    "clip = 1.0\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-05, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "# scheduler = \n",
    "\n",
    "train_loss_set = []\n",
    "dev_loss_set = []\n",
    "dev_f_beta_set = []\n",
    "dev_f1_set = []\n",
    "\n",
    "for epoch in range(epochs) : \n",
    "    print(f'------------------------ \\n Epochs {epoch+1}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, device, accumulation_steps, train_dataset, train_data_loader, loss_fn, optimizer, batch_size, clip)\n",
    "    dev_loss, dev_f_beta , dev_f1 = evaluate(model, device, tokenizer, dev_data_loader, loss_fn, beam_size = 1, batch_size = batch_size)\n",
    "\n",
    "    train_loss_set.append(train_loss)\n",
    "    dev_loss_set.append(dev_loss)\n",
    "    dev_f_beta_set.append(dev_f_beta)\n",
    "    dev_f1_set.append(dev_f1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Epoch took : {end_time-start_time}')\n",
    "    torch.save(model.state_dict(), root_path + 'roberta/roberta_qa_checkpoint.pt')\n",
    "    \n",
    "plot_curves(epochs, train_loss_set, dev_loss_set, dev_f_beta_set, dev_f1_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw7IHJ5h1yq3"
   },
   "source": [
    "## 2 - Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5498,
     "status": "ok",
     "timestamp": 1632251265420,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "XNhNImwu1yq3",
    "outputId": "7358c945-1cd8-4dbf-ffee-2cb219b36173",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "F_05_Score, pred_by_doc = test(tokenizer, 1, model, device, test_data_loader, test_dataset)\n",
    "print(F_05_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1632242484713,
     "user": {
      "displayName": "Simon Ebel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjk20RS8gkw1uAaPoheFBQw5r-OAvxMeX8qh0REkg=s64",
      "userId": "15738812401286177053"
     },
     "user_tz": -120
    },
    "id": "B4s9kBb7hjXq",
    "outputId": "84b2f9da-7dfb-4786-e4fb-96912065822e"
   },
   "outputs": [],
   "source": [
    "# idc = 437\n",
    "\n",
    "# print(pred_by_doc[idc]['truth'])\n",
    "# pred_by_doc[idc]['pred']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1 - Roberta.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
